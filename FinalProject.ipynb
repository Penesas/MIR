{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Music genre classification\n",
    "\n",
    "Music information retrieval is the interdisciplinary science of retrieving information from music.\n",
    "As the deep learning has become so popular recently, many related researches are available on the internet. \n",
    "\n",
    "I will use Keras for this project.\n",
    "\n",
    "First part was processing the audio file into data base and separate them into training data and test data.\n",
    "GTZAN genre data set has 10 genres, each of genre has 100 songs, and each song last 30 seconds. \n",
    "The basic idea of process is to transform them into frequency spectrum and using Mel Frequency Cepstral Coefficients which has been used for lab07. These processes are already available from the python code that I include in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read 1000 audio files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "device = 'cpu'\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd # Pandas for reading CSV files and easier Data handling in preparation\n",
    "from os.path import join\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inline \n",
    "\n",
    "# Local imports\n",
    "import rp_extract as rp\n",
    "from audiofile_read import audiofile_read\n",
    "# SET YOUR OWN PATH HERE\n",
    "AUDIO_PATH = 'data'\n",
    "\n",
    "csv_file = join(AUDIO_PATH,'filelist_GTZAN_mp3_wclasses.txt')\n",
    "metadata = pd.read_csv(csv_file, index_col=0, header=None)\n",
    "\n",
    "# create list of filenames with associated classes\n",
    "filelist = metadata.index.tolist()\n",
    "classes = metadata[1].values.tolist()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(classes)\n",
    "\n",
    "# we keep (and print) the number of classis\n",
    "n_classes = len(labelencoder.classes_)\n",
    "\n",
    "classes_num = labelencoder.transform(classes)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# make a row vector a column vector, as needed by OneHotEncoder, using reshape(-1,1) \n",
    "classes_num_col = classes_num.reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "classes_num_1hot = encoder.fit_transform(classes_num_col)\n",
    "\n",
    "list_spectrograms = [] # spectrograms are put into a list first\n",
    "\n",
    "# desired output parameters\n",
    "n_mel_bands = 40   # y axis\n",
    "frames = 80        # x axis\n",
    "\n",
    "# some FFT parameters\n",
    "fft_window_size=1024 #512\n",
    "fft_overlap = 0.5\n",
    "hop_size = int(fft_window_size*(1-fft_overlap))\n",
    "segment_size = fft_window_size + (frames-1) * hop_size # segment size for desired # frames\n",
    "\n",
    "for filename in filelist:\n",
    "    #print (\".\") \n",
    "    filepath = os.path.join(AUDIO_PATH, filename)\n",
    "    samplerate, samplewidth, wavedata = audiofile_read(filepath,verbose=False)\n",
    "    sample_length = wavedata.shape[0]\n",
    "\n",
    "    # make Mono (in case of multiple channels / stereo)\n",
    "    if wavedata.ndim > 1:\n",
    "        wavedata = np.mean(wavedata, 1)\n",
    "      \n",
    "    pos = int(sample_length / 2 - segment_size / 2)\n",
    "    wav_segment = wavedata[pos:pos+segment_size]\n",
    "    \n",
    "    # AUDIO PRE-PROCESSING\n",
    "\n",
    "    # 1) FFT spectrogram \n",
    "    spectrogram = rp.calc_spectrogram(wav_segment,fft_window_size,fft_overlap)\n",
    "\n",
    "    # 2) Transform to perceptual Mel scale (uses librosa.filters.mel)\n",
    "    spectrogram = rp.transform2mel(spectrogram,samplerate,fft_window_size,n_mel_bands)\n",
    "        \n",
    "    # 3) Log 10 transform\n",
    "    spectrogram = np.log10(spectrogram)\n",
    "    \n",
    "    list_spectrograms.append(spectrogram)\n",
    "        \n",
    "print (\"\\nRead\", len(filelist), \"audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I made some changes on the code to improve the resulte. I assume that human ear has trouble to hear very low bass sound, so to classify a music genre is less relative for these sound. Therefore the weight of them would be small and if the data set is not sufficent to neglecte them, they would cause negetive effect to the result.\n",
    "From the result, I found the lowest 2 frequency band would reduce the accuracy, so I drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "voidmel = 2\n",
    "\n",
    "for i in range(len(list_spectrograms)):\n",
    "    for j in range(voidmel):\n",
    "        list_spectrograms[i][j,:] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I seperate the date into train data and test data. For each genre, there are 75 train data and 25 test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(list_spectrograms)\n",
    "N, ydim, xdim = data.shape\n",
    "data = data.reshape(N, xdim*ydim)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "testset_size = 0.25\n",
    "train_set, test_set, train_classes, test_classes = train_test_split(data, classes_num, test_size=testset_size, random_state=0)\n",
    "from collections import Counter\n",
    "cnt = Counter(train_classes)\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=testset_size, random_state=0)\n",
    "splits = splitter.split(data, classes_num)\n",
    "\n",
    "for train_index, test_index in splits:\n",
    "    # split the data\n",
    "    train_set = data[train_index]\n",
    "    test_set = data[test_index]\n",
    "    \n",
    "    # and the numeric classes (groundtruth)\n",
    "    train_classes = classes_num[train_index]\n",
    "    train_classes_1hot = classes_num_1hot[train_index]  # 1 hot we need for traning\n",
    "    test_classes = classes_num[test_index]\n",
    "cnt = Counter(train_classes)\n",
    "n_channels = 1 # 1 for grey-scale, 3 for RGB (in this case usually already present in the data)\n",
    "\n",
    "train_set = train_set.reshape(train_set.shape[0], ydim, xdim, n_channels)\n",
    "test_set = test_set.reshape(test_set.shape[0], ydim, xdim, n_channels)\n",
    "input_shape = train_set.shape[1:]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hidden layer, I choose Rectified linear unit(ReLU) as my activation funciton, comparing with other activation function, I found this one works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\tian\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (10, 4), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "d:\\users\\tian\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (4, 10), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "d:\\users\\tian\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "d:\\users\\tian\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "d:\\users\\tian\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "n_filters = 16  # e.g. 16 or 32 \n",
    "dropout = 0.25 # None or 0 < dropout < 1\n",
    "# Input only specifies the input shape\n",
    "input = Input(input_shape)\n",
    "\n",
    "# CNN layers\n",
    "# specify desired number of filters\n",
    "\n",
    "# The functional API allows to specify the predecessor in (brackets) after the new Layer function call\n",
    "conv_layer1 = Conv2D(n_filters, 10, 4, activation='relu')(input)  # a vertical filter\n",
    "conv_layer2 = Conv2D(n_filters, 4, 10, activation='relu')(input)  # a horizontal filter\n",
    "\n",
    "# LARGER Pooling layers - complementary to vertical/horizontal filter\n",
    "maxpool1 = MaxPooling2D(pool_size=(1,5))(conv_layer1)\n",
    "maxpool2 = MaxPooling2D(pool_size=(5,1))(conv_layer2) # used 4,1 first\n",
    "\n",
    "# Dropout for both layers\n",
    "if dropout:\n",
    "    maxpool1 = Dropout(dropout)(maxpool1)\n",
    "    maxpool2 = Dropout(dropout)(maxpool2)\n",
    "\n",
    "# we have to flatten the Pooling output in order to be concatenated\n",
    "poolflat1 = Flatten()(maxpool1)\n",
    "poolflat2 = Flatten()(maxpool2)\n",
    "\n",
    "# Merge the 2 parallel pipelines\n",
    "merged = merge([poolflat1, poolflat2], mode='concat')\n",
    "\n",
    "full = Dense(256, activation='sigmoid')(merged)\n",
    "output_layer = Dense(n_classes, activation='softmax')(full)\n",
    "\n",
    "# finally create the model\n",
    "model = Model(input=input, output=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent(SGD) could also produce a great result, but I found Adam was much fater and have a little higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# Define a loss function \n",
    "loss = 'categorical_crossentropy' \n",
    "#loss = 'binary_crossentropy' \n",
    "\n",
    "opt = optimizers.Adam(lr = 0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "opt2 = 'sgd' \n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "750/750 [==============================] - 5s - loss: 2.3007 - acc: 0.2307     \n",
      "Epoch 2/15\n",
      "750/750 [==============================] - 5s - loss: 1.6868 - acc: 0.4253     \n",
      "Epoch 3/15\n",
      "750/750 [==============================] - 5s - loss: 1.3251 - acc: 0.6040     \n",
      "Epoch 4/15\n",
      "750/750 [==============================] - 5s - loss: 1.0613 - acc: 0.6880     \n",
      "Epoch 5/15\n",
      "750/750 [==============================] - 6s - loss: 0.8225 - acc: 0.7827     \n",
      "Epoch 6/15\n",
      "750/750 [==============================] - 5s - loss: 0.6111 - acc: 0.8627     \n",
      "Epoch 7/15\n",
      "750/750 [==============================] - 5s - loss: 0.4630 - acc: 0.9160     \n",
      "Epoch 8/15\n",
      "750/750 [==============================] - 5s - loss: 0.3211 - acc: 0.9573     \n",
      "Epoch 9/15\n",
      "750/750 [==============================] - 5s - loss: 0.2256 - acc: 0.9827     \n",
      "Epoch 10/15\n",
      "750/750 [==============================] - 4s - loss: 0.1510 - acc: 0.9920     \n",
      "Epoch 11/15\n",
      "750/750 [==============================] - 5s - loss: 0.1066 - acc: 0.9987     \n",
      "Epoch 12/15\n",
      "750/750 [==============================] - 5s - loss: 0.0839 - acc: 1.0000     \n",
      "Epoch 13/15\n",
      "750/750 [==============================] - 7s - loss: 0.0665 - acc: 1.0000     \n",
      "Epoch 14/15\n",
      "750/750 [==============================] - 7s - loss: 0.0508 - acc: 1.0000     \n",
      "Epoch 15/15\n",
      "750/750 [==============================] - 7s - loss: 0.0423 - acc: 1.0000     \n"
     ]
    }
   ],
   "source": [
    "History = model.fit(train_set, train_classes_1hot, batch_size=32, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55200000000000005"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(test_set)\n",
    "test_pred = np.argmax(test_pred, axis=1)\n",
    "accuracy_score(test_classes, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result accuracy is around 53% to 55%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
